# players.py
import copy
import random

from matplotlib.ticker import MaxNLocator

from game import Game, state_list2state_array, array2string, string2array, move_id2move_action, move_action2move_id, Board
from mcts import MCTSPlayer
import csv
import os
import matplotlib.pyplot as plt
from matplotlib import rcParams
import os
from openai import OpenAI

from pytorch_net import PolicyValueNet

# è¨­å®šä¸­æ–‡å­—é«”ï¼ˆä»¥ Windows ç‚ºä¾‹ï¼‰
rcParams['font.sans-serif'] = ['Microsoft JhengHei']  # å¾®è»Ÿæ­£é»‘é«”
rcParams['axes.unicode_minus'] = False


class MinimaxDarkChessPlayer:
    """æš—æ£‹ Alphaâ€“Beta + å‘ä¸Šå‚³é + å¯§éœæœå°‹ AI ç©å®¶"""

    def __init__(self, search_depth=4):
        self.game = None
        self.depth = search_depth
        self.player = None
        self.agent = "AI"

    def set_player_ind(self, p):
        """è¨­å®šç©å®¶ç·¨è™Ÿï¼š1=ç´…, 2=é»‘"""
        self.player = p

    # ====================== æ”¹è‰¯ç‰ˆæœå°‹ ======================
    def quiescence_search(self, board, alpha, beta, side_player_id, maxDepth, depth):
        """å¯§éœæœå°‹ï¼šåªå±•é–‹åƒå­ç›´åˆ°ç©©å®šã€‚"""
        eat_moves, _ = board.greedys()
        if not eat_moves:
            return 0

        best = -float("inf")
        for move in eat_moves:
            backup = self._backup_board(board)
            reward = board.do_move(move)  # reward ç‚ºåƒå­åˆ†æ•¸ï¼ˆæ­£ä»£è¡¨åƒå°æ–¹ï¼‰
            # value = è©²åƒå­åˆ†æ•¸ + åŒå±¤æ·±åº¦ bonus
            bonus = (maxDepth - depth)
            value = reward + bonus
            # éè¿´åƒåˆ°åº•
            value -= self.quiescence_search(board, -beta, -alpha, side_player_id, maxDepth, depth + 1)
            self._restore_board(board, backup)

            if value > best:
                best = value
            if best > alpha:
                alpha = best
            if alpha >= beta:
                break
        return best

    def search_upward(self, board, depth, alpha, beta, side_player_id, maxDepth):
        """å‘ä¸Šå‚³é + åŒåˆ†æ­¥è™•ç† + å–®å‘æœå°‹ (negamax style)"""
        # --- çµ‚æ­¢æ¢ä»¶ ---
        if depth == 0:
            eat_moves, _ = board.greedys()
            if eat_moves:
                return self.quiescence_search(board, alpha, beta, side_player_id, maxDepth, 0)
            return 0

        eat_moves, fallback_moves = board.greedys()
        legal_moves = eat_moves + fallback_moves
        if not legal_moves:
            return 0

        value_accum = -float("inf")
        all_zero_scores = True

        for move in legal_moves:
            backup = self._backup_board(board)
            reward = board.do_move(move)  # reward ç‚ºåƒå­åŠ æ¬Šå€¼ï¼ˆæ­£ï¼šåƒå°æ‰‹ï¼Œè² ï¼šè¢«åƒï¼‰
            # åˆå§‹åˆ†å€¼ï¼šè‹¥æœ‰åƒå­å‰‡åŠ ä¸ŠåŒåˆ†æ­¥bonus
            value_here = 0
            if reward != 0:
                bonus = (maxDepth - depth)
                value_here += reward + bonus
                child_depth = depth if depth == maxDepth - 1 else depth - 1
                value_here -= self.search_upward(board, child_depth, -beta, -alpha, side_player_id, maxDepth)
            else:
                value_here -= self.search_upward(board, depth - 1, -beta, -alpha, side_player_id, maxDepth)

            self._restore_board(board, backup)

            if value_here > value_accum:
                value_accum = value_here
            if value_accum > alpha:
                alpha = value_accum
            if alpha >= beta:
                break

            if value_here != 0:
                all_zero_scores = False

        # --- å–®å‘æœå°‹ï¼ˆç•¶æ‰€æœ‰å€™é¸çš†ç‚º 0ï¼‰ ---
        if all_zero_scores and depth > 1:
            one_way_best = -float("inf")
            eat_moves2, fallback_moves2 = board.greedys()
            for move in eat_moves2 + fallback_moves2:
                backup = self._backup_board(board)
                reward = board.do_move(move)
                val = reward - self.search_upward(board, depth - 1, -beta, -alpha, side_player_id, maxDepth)
                self._restore_board(board, backup)
                if val > one_way_best:
                    one_way_best = val
                if one_way_best > alpha:
                    alpha = one_way_best
                if alpha >= beta:
                    break
            if one_way_best > value_accum:
                value_accum = one_way_best

        return value_accum

    # ====================== å‹•ä½œé¸æ“‡ ======================
    def get_action(self, board):
        """å–å¾—ä¸‹ä¸€æ­¥è¡Œå‹•"""
        self.game = Game(board)
        eat_moves, fallback_moves = board.greedys()
        legal_moves = eat_moves + fallback_moves
        if not legal_moves:
            return None

        # æœ‰åƒå­ â†’ ç”¨æ–°æœå°‹æ³•
        if eat_moves:
            best_value = -float("inf")
            best_move = None
            alpha, beta = -float("inf"), float("inf")
            side_player_id = board.current_player_id
            maxDepth = self.depth

            for move in eat_moves:
                backup = self._backup_board(board)
                reward = board.do_move(move)
                value_here = reward
                if reward != 0:
                    bonus = (maxDepth - 1)
                    value_here += bonus
                    value_here -= self.search_upward(board, maxDepth - 1, -beta, -alpha, side_player_id, maxDepth)
                else:
                    value_here -= self.search_upward(board, maxDepth - 1, -beta, -alpha, side_player_id, maxDepth)
                self._restore_board(board, backup)

                if value_here > best_value:
                    best_value = value_here
                    best_move = move

            return best_move
        else:
            # æ²’åƒå­ â†’ ç¿»å­ç­–ç•¥
            return self._reveal_strategy(board)

        # ================== ç¿»å­ç­–ç•¥ ==================

    def _reveal_strategy(self, board):
        """æ¨¡æ“¬ç¿»å­æœŸæœ›å€¼ï¼ŒæŒ‘å‡ºæœ€æœ‰åˆ©çš„ç¿»å­ä½ç½®"""
        dark_positions = board.get_dark_positions()
        if not dark_positions:
            return random.choice(board.availables)  # æ²’å¾—ç¿»å°±éš¨ä¾¿èµ°

        best_pos = None
        best_value = -float('inf')

        for pos in dark_positions:
            expected_value = self._simulate_reveal(board, pos)
            if expected_value > best_value:
                best_value = expected_value
                best_pos = pos

        r, c = best_pos
        action = f"{r}{c}{r}{c}"
        return move_action2move_id[action]

    def _simulate_reveal(self, board, pos):
        """æ¨¡æ“¬ç¿»å‡ºä¸åŒæ£‹å­å¾Œçš„æœŸæœ›å€¼ï¼ˆçµåˆæ–°æœå°‹æ³•ï¼‰"""
        re_pieces = board.remain_pieces
        if not re_pieces:
            return 0

        # çµ±è¨ˆæ£‹ç¨®æ©Ÿç‡
        counts = {}
        for p in re_pieces:
            counts[p] = counts.get(p, 0) + 1
        total = len(re_pieces)
        possible_pieces = {p: c / total for p, c in counts.items()}

        total_value = 0
        for piece, prob in possible_pieces.items():
            backup = self._backup_board(board)
            board.force_reveal(pos, piece)

            # ğŸ”„ æ”¹æˆå‘¼å«æ–°æœå°‹å™¨ search_upward
            score = self.search_upward(
                board, depth=2,
                alpha=-float('inf'),
                beta=float('inf'),
                side_player_id=board.current_player_id,
                maxDepth=2
            )

            total_value += prob * score
            self._restore_board(board, backup)

        return total_value

    # ====================== è©•ä¼°èˆ‡å‚™ä»½ ======================
    def evaluate(self, board, winner=None):
        """ç›¤é¢è©•ä¼°"""
        if winner == self.player:
            return 9999
        elif winner != -1 and winner != self.player:
            return -9999

        red_strength = board.calc_side_strength('çº¢')
        black_strength = board.calc_side_strength('é»‘')
        return red_strength - black_strength if self.player == 1 else black_strength - red_strength

    def _backup_board(self, board):
        """å‚™ä»½æ£‹ç›¤ç‹€æ…‹"""
        return {
            "state_deque": copy.deepcopy(board.state_deque),
            "remain_pieces": copy.deepcopy(board.remain_pieces),
            "current_player_color": board.current_player_color,
            "current_player_id": board.current_player_id,
            "last_move": board.last_move,
            "winner": board.winner,
            "kill_action": board.kill_action,
            "first_move": board.first_move,
            "action_count": board.action_count,
        }

    def _restore_board(self, board, backup):
        """é‚„åŸæ£‹ç›¤ç‹€æ…‹"""
        board.state_deque = backup["state_deque"]
        board.remain_pieces = backup["remain_pieces"]
        board.current_player_color = backup["current_player_color"]
        board.current_player_id = backup["current_player_id"]
        board.last_move = backup["last_move"]
        board.winner = backup["winner"]
        board.kill_action = backup["kill_action"]
        board.first_move = backup["first_move"]
        board.action_count = backup["action_count"]


class ChatGPTPlayer:
    def __init__(self, model="gpt-4o-mini"):
        self.client = OpenAI(api_key="")  # æ”¾ API Key

        self.model = model
        self.agent = 'AI'

    def set_player_ind(self, p):
        self.player = p

    def board_to_state(self, _state_array):
        # _state_array: [10, 9, 7], HWC
        all_board = []

        for i in range(4):
            board_line = []
            for j in range(8):
                board_line.append(array2string(_state_array[i][j]))
            all_board.append(board_line)
        return all_board

    def get_action(self, board):
        # è½‰æ›æ£‹ç›¤
        state_text = self.board_to_state(state_list2state_array(board.state_deque[-1]))

        # æŠŠæ‰€æœ‰åˆæ³•è¡Œå‹•åˆ—å‡ºä¾†
        eat_move_list, fallback_movelist = board.greedys()
        all_moves = eat_move_list + fallback_movelist
        all_moves_relabel = [move_id2move_action[m] for m in all_moves]
        # ç”Ÿæˆ prompt
        # print(all_moves_relabel)
        prompt = f"""
ä½ æ­£åœ¨ç©ä¸­åœ‹æš—æ£‹ (4x8)ã€‚
ç¾åœ¨æ£‹ç›¤ç‹€æ…‹å¦‚ä¸‹ï¼š
{state_text}

å¯è¡Œçš„å‹•ä½œæœ‰ï¼š
{all_moves_relabel} 
æ ¼å¼æ˜¯4å€‹æ•¸å­— ABCD ABç‚ºèµ·å§‹ä½ç½® CDç‚ºçµæŸä½ç½® è‹¥A=C B=Då‰‡ä»£è¡¨ç¿»æ£‹

è«‹å¾ä¸­é¸æ“‡ä¸€å€‹æœ€ä½³å‹•ä½œï¼Œç›´æ¥è¼¸å‡ºè©²å‹•ä½œ (ä¸è¦å¤šé¤˜çš„è§£é‡‹)ã€‚
"""

        try:
            # å‘¼å« ChatGPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.9
            )
            reply = response.choices[0].message.content.strip()
            reply_str = "".join(str(x) for x in reply if x.isdigit())  # éæ¿¾éæ•¸å­—

            # å˜—è©¦è½‰æ›
            if reply_str in move_action2move_id:
                reply_index = move_action2move_id[reply_str]
                # ç¢ºä¿å‹•ä½œåˆæ³•
                if reply_index in all_moves:
                    return reply_index
                else:
                    print(f"âš ï¸ ChatGPT å›å‚³éæ³•å‹•ä½œ {reply_str}ï¼ˆä¸åœ¨åˆæ³•å‹•ä½œåˆ—è¡¨ï¼‰ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")
            else:
                print(f"âš ï¸ ChatGPT å›å‚³ç„¡æ•ˆå‹•ä½œå­—ä¸² {reply}ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")

        except Exception as e:
            print(f"âš ï¸ ChatGPT API éŒ¯èª¤: {e}ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")

            # fallback
        return random.choice(all_moves) if all_moves else None

class RandomPlayer:
    def __init__(self):
        self.agent = 'AI'
        self.type = "random"

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        eat_move_list, fallback_move_list = board.greedys()
        all_move = eat_move_list + fallback_move_list
        if not all_move:
            return None
        return random.choice(all_move)


class GreedyPlayer:
    def __init__(self):
        self.agent = 'AI'
        self.type = "greedy"

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        eat_move_list, fallback_move_list = board.greedys()
        if eat_move_list:
            return random.choice(eat_move_list)
        elif fallback_move_list:
            return random.choice(fallback_move_list)
        else:
            return None


class Human:
    def __init__(self):
        self.agent = 'Human'

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        # UIplay æœƒç”¨ï¼Œé€™è£¡å…ˆæ”¾ä½”ä½
        return None



def battle_summary(player1, opponents, board, playouts, n_games=100,
                   save_csv=True, csv_file="battle_summary.csv"):
    """
    å°æ¯å€‹å°æ‰‹é€²è¡Œå°æˆ°ä¸¦è¨˜éŒ„çµæœã€‚
    è‹¥ CSV å·²å­˜åœ¨ï¼Œå‰‡åªæœƒè¿½åŠ æ–°å°æ‰‹çš„çµæœï¼ˆä¸è¦†è“‹èˆŠè³‡æ–™ï¼‰ã€‚
    """
    game = Game(board)
    results = {}

    existing_opponents = set()
    writer = None
    f = None

    # --- æª¢æŸ¥æ˜¯å¦å·²æœ‰çµæœæª” ---
    if os.path.exists(csv_file):
        with open(csv_file, "r", encoding="utf-8") as f_read:
            reader = csv.reader(f_read)
            next(reader, None)  # skip header
            for row in reader:
                if len(row) >= 1:
                    existing_opponents.add(row[0])

    # --- é–‹å•Ÿ CSV æª”æ¡ˆ ---
    if save_csv:
        file_exists = os.path.exists(csv_file)
        f = open(csv_file, "a", newline="", encoding="utf-8")
        writer = csv.writer(f)
        # å¦‚æœæ˜¯æ–°æª”æ¡ˆå°±å¯«å…¥æ¨™é ­
        if not file_exists:
            writer.writerow(["Opponent", "Wins", "Losses", "Draws"])

    # --- é€ä¸€å°æˆ° ---
    for opp_name, player2 in opponents.items():
        if opp_name in existing_opponents:
            print(f"âš ï¸ {opp_name} å·²å­˜åœ¨æ–¼ {csv_file}ï¼Œè·³éã€‚")
            continue

        stats = {"win": 0, "loss": 0, "draw": 0}
        print(f"âš”ï¸ {player1.agent} vs {opp_name} é–‹å§‹å°æˆ°ï¼Œå…± {n_games} å ´...")

        for i in range(n_games):
            board.init_board(1)
            players = {1: player1, 2: player2}

            # è¼ªæµå…ˆæ‰‹
            if i % 2 == 0:
                player1.set_player_ind(1)
                player2.set_player_ind(2)
            else:
                player1.set_player_ind(2)
                player2.set_player_ind(1)

            while True:
                move = players[board.current_player_id].get_action(board)
                if move is None:
                    break
                board.do_move(move)
                end, winner = board.game_end()
                if end:
                    print(f"ç¬¬{i}å ´çµæŸ")
                    if winner == -1:
                        stats["draw"] += 1
                    elif players[winner] == player1:
                        stats["win"] += 1
                    else:
                        stats["loss"] += 1
                    break

        results[opp_name] = stats
        print(f"âœ… {player1.agent} vs {opp_name} å®Œæˆ: {stats}")

        # --- å¯«å…¥çµæœ ---
        if writer:
            writer.writerow([opp_name, stats["win"], stats["loss"], stats["draw"]])
            f.flush()

    if f:
        f.close()
        print(f"ğŸ“Š å°æˆ°çµæœå·²æ›´æ–°è‡³ {csv_file}")

    return results

def plot_battle_results_from_csv(csv_file="battle_summary.csv"):
    import csv
    import matplotlib.pyplot as plt
    import numpy as np
    from matplotlib.transforms import blended_transform_factory

    opponents = []
    wins = []
    draws = []
    losses = []

    # --- è®€å– CSV ---
    with open(csv_file, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            opponents.append(row.get("Opponent", "").strip())

            def to_int(x):
                try:
                    return int(x)
                except:
                    return 0

            wins.append(to_int(row.get("Wins", 0)))
            losses.append(to_int(row.get("Losses", 0)))
            draws.append(to_int(row.get("Draws", 0)))

    if not opponents:
        print("CSV æ²’æœ‰è®€åˆ°è³‡æ–™")
        return

    # --- ä¾ Wins æ’åº ---
    order = sorted(range(len(opponents)), key=lambda i: wins[i], reverse=False)
    opponents = [opponents[i] for i in order]
    wins = [wins[i] for i in order]
    draws = [draws[i] for i in order]
    losses = [losses[i] for i in order]

    # --- é¡è‰² ---
    color_win = "#4A90E2"   # è—
    color_draw = "#7F8C8D"  # ç°
    color_loss = "#E74C3C"  # ç´…

    y = np.arange(len(opponents))
    height = 0.6

    # èª¿æ•´ figsize èˆ‡å·¦é‚Šé‚Šç•Œï¼ˆé¿å…å·¦å´æ–‡å­—è¢«è£åˆ‡ï¼‰
    fig, ax = plt.subplots(figsize=(5.5, max(4, len(opponents) * 0.6)))
    fig.subplots_adjust(left=0.20, right=0.95)  # left è¶Šå¤§ï¼Œè»¸å¤–å¯æ”¾çš„ç©ºé–“è¶Šå¤š

    # Barsï¼ˆå¾ x=0 é–‹å§‹ï¼‰
    win_bars = ax.barh(y, wins, height=height, color=color_win, edgecolor="black")
    draw_bars = ax.barh(y, draws, height=height, left=wins, color=color_draw, edgecolor="black")
    left_for_losses = [w + d for w, d in zip(wins, draws)]
    loss_bars = ax.barh(y, losses, height=height, left=left_for_losses, color=color_loss, edgecolor="black")

    # æ¨™è¨»æ¯å€‹å€å¡Šæ•¸å­—ï¼ˆ>0 æ‰é¡¯ç¤ºï¼‰
    def annotate(bars):
        for bar in bars:
            w = bar.get_width()
            if w > 0:
                ax.text(bar.get_x() + w / 2,
                        bar.get_y() + bar.get_height() / 2,
                        str(int(w)),
                        va="center", ha="center",
                        fontsize=9,
                        color="white" if w > 10 else "black")
    annotate(win_bars)
    annotate(draw_bars)
    annotate(loss_bars)

    # --- æŠŠå°æ‰‹åç¨±é¡¯ç¤ºåœ¨å³é‚Šï¼ˆè·Ÿä¹‹å‰è¡Œç‚ºä¸€è‡´ï¼‰---
    ax.yaxis.tick_right()
    ax.set_yticks(y)
    ax.set_yticklabels(opponents, fontsize=11)

    # --- åœ¨ bar å·¦å´è»¸å¤–æ”¾ç½® "æš—æ£‹ Alpha"ï¼ˆx ç”¨ axes fractionï¼Œy ç”¨ dataï¼‰---
    # blended transform: (x in axes coords, y in data coords)
    trans = blended_transform_factory(ax.transAxes, ax.transData)
    # æ”¾åœ¨ axes fraction çš„ -0.02ï¼ˆç•¥åœ¨è»¸å¤–ï¼‰ï¼Œè‹¥è¦æ›´å¤–å¯èª¿åˆ° -0.04 æˆ– -0.01
    x_axes_pos = -0.02
    for yi in y:
        ax.text(x_axes_pos, yi, "æš—æ£‹é˜¿æ‹‰æ³•",
                transform=trans,
                ha="right", va="center", fontsize=11,
                clip_on=False)  # å…è¨±ç•«åœ¨è»¸å¤–

    # æ¨™é¡Œèˆ‡æ ¼å¼
    ax.set_title("æš—æ£‹é˜¿æ‹‰æ³•å°æˆ°çµæœ", fontsize=15, weight="bold")
    ax.set_xlabel("å ´æ•¸", fontsize=12)
    ax.grid(axis="x", linestyle="--", alpha=0.35)

    # x è»¸ä¸Šç•Œï¼ˆå¾ 0 é–‹å§‹ï¼‰
    total_max = max(w + d + l for w, d, l in zip(wins, draws, losses))
    ax.set_xlim(0, total_max + max(5, int(total_max * 0.05)))

    # ç§»é™¤åœ–ä¾‹ï¼ˆä½ å…ˆå‰è¦æ±‚ï¼‰
    # ï¼ˆè‹¥ä½ ä¹‹å¾Œæƒ³è¦åœ–ä¾‹ï¼Œå¯åè¨»è§£ä¸‹é¢ä¸‰è¡Œï¼‰
    # from matplotlib.patches import Patch
    # ax.legend(handles=[Patch(facecolor=color_win), Patch(facecolor=color_draw), Patch(facecolor=color_loss)], labels=["Wins","Draws","Losses"])

    plt.tight_layout()
    plt.show()

if __name__ == '__main__':

    plot_battle_results_from_csv()