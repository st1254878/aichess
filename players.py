# players.py
import copy
import random

from matplotlib.ticker import MaxNLocator

from game import Game, state_list2state_array, array2string, string2array, move_id2move_action, move_action2move_id, Board
from mcts import MCTSPlayer
import csv
import os
import matplotlib.pyplot as plt
from matplotlib import rcParams
import os
from openai import OpenAI

from pytorch_net import PolicyValueNet

# è¨­å®šä¸­æ–‡å­—é«”ï¼ˆä»¥ Windows ç‚ºä¾‹ï¼‰
rcParams['font.sans-serif'] = ['Microsoft JhengHei']  # å¾®è»Ÿæ­£é»‘é«”
rcParams['axes.unicode_minus'] = False


class MinimaxDarkChessPlayer:
    """æš—æ£‹ Alphaâ€“Beta + å‘ä¸Šå‚³é + å¯§éœæœå°‹ AI ç©å®¶"""

    def __init__(self, search_depth=4):
        self.game = None
        self.depth = search_depth
        self.player = None
        self.agent = "AI"

    def set_player_ind(self, p):
        """è¨­å®šç©å®¶ç·¨è™Ÿï¼š1=ç´…, 2=é»‘"""
        self.player = p

    # ====================== æ”¹è‰¯ç‰ˆæœå°‹ ======================
    def quiescence_search(self, board, alpha, beta, side_player_id, maxDepth, depth):
        """å¯§éœæœå°‹ï¼šåªå±•é–‹åƒå­ç›´åˆ°ç©©å®šã€‚"""
        eat_moves, _ = board.greedys()
        if not eat_moves:
            return 0

        best = -float("inf")
        for move in eat_moves:
            backup = self._backup_board(board)
            reward = board.do_move(move)  # reward ç‚ºåƒå­åˆ†æ•¸ï¼ˆæ­£ä»£è¡¨åƒå°æ–¹ï¼‰
            # value = è©²åƒå­åˆ†æ•¸ + åŒå±¤æ·±åº¦ bonus
            bonus = (maxDepth - depth)
            value = reward + bonus
            # éè¿´åƒåˆ°åº•
            value -= self.quiescence_search(board, -beta, -alpha, side_player_id, maxDepth, depth + 1)
            self._restore_board(board, backup)

            if value > best:
                best = value
            if best > alpha:
                alpha = best
            if alpha >= beta:
                break
        return best

    def search_upward(self, board, depth, alpha, beta, side_player_id, maxDepth):
        """å‘ä¸Šå‚³é + åŒåˆ†æ­¥è™•ç† + å–®å‘æœå°‹ (negamax style)"""
        # --- çµ‚æ­¢æ¢ä»¶ ---
        if depth == 0:
            eat_moves, _ = board.greedys()
            if eat_moves:
                return self.quiescence_search(board, alpha, beta, side_player_id, maxDepth, 0)
            return 0

        eat_moves, fallback_moves = board.greedys()
        legal_moves = eat_moves + fallback_moves
        if not legal_moves:
            return 0

        value_accum = -float("inf")
        all_zero_scores = True

        for move in legal_moves:
            backup = self._backup_board(board)
            reward = board.do_move(move)  # reward ç‚ºåƒå­åŠ æ¬Šå€¼ï¼ˆæ­£ï¼šåƒå°æ‰‹ï¼Œè² ï¼šè¢«åƒï¼‰
            # åˆå§‹åˆ†å€¼ï¼šè‹¥æœ‰åƒå­å‰‡åŠ ä¸ŠåŒåˆ†æ­¥bonus
            value_here = 0
            if reward != 0:
                bonus = (maxDepth - depth)
                value_here += reward + bonus
                child_depth = depth if depth == maxDepth - 1 else depth - 1
                value_here -= self.search_upward(board, child_depth, -beta, -alpha, side_player_id, maxDepth)
            else:
                value_here -= self.search_upward(board, depth - 1, -beta, -alpha, side_player_id, maxDepth)

            self._restore_board(board, backup)

            if value_here > value_accum:
                value_accum = value_here
            if value_accum > alpha:
                alpha = value_accum
            if alpha >= beta:
                break

            if value_here != 0:
                all_zero_scores = False

        # --- å–®å‘æœå°‹ï¼ˆç•¶æ‰€æœ‰å€™é¸çš†ç‚º 0ï¼‰ ---
        if all_zero_scores and depth > 1:
            one_way_best = -float("inf")
            eat_moves2, fallback_moves2 = board.greedys()
            for move in eat_moves2 + fallback_moves2:
                backup = self._backup_board(board)
                reward = board.do_move(move)
                val = reward - self.search_upward(board, depth - 1, -beta, -alpha, side_player_id, maxDepth)
                self._restore_board(board, backup)
                if val > one_way_best:
                    one_way_best = val
                if one_way_best > alpha:
                    alpha = one_way_best
                if alpha >= beta:
                    break
            if one_way_best > value_accum:
                value_accum = one_way_best

        return value_accum

    # ====================== å‹•ä½œé¸æ“‡ ======================
    def get_action(self, board):
        """å–å¾—ä¸‹ä¸€æ­¥è¡Œå‹•"""
        self.game = Game(board)
        eat_moves, fallback_moves = board.greedys()
        legal_moves = eat_moves + fallback_moves
        if not legal_moves:
            return None

        # æœ‰åƒå­ â†’ ç”¨æ–°æœå°‹æ³•
        if eat_moves:
            best_value = -float("inf")
            best_move = None
            alpha, beta = -float("inf"), float("inf")
            side_player_id = board.current_player_id
            maxDepth = self.depth

            for move in eat_moves:
                backup = self._backup_board(board)
                reward = board.do_move(move)
                value_here = reward
                if reward != 0:
                    bonus = (maxDepth - 1)
                    value_here += bonus
                    value_here -= self.search_upward(board, maxDepth - 1, -beta, -alpha, side_player_id, maxDepth)
                else:
                    value_here -= self.search_upward(board, maxDepth - 1, -beta, -alpha, side_player_id, maxDepth)
                self._restore_board(board, backup)

                if value_here > best_value:
                    best_value = value_here
                    best_move = move

            return best_move
        else:
            # æ²’åƒå­ â†’ ç¿»å­ç­–ç•¥
            return self._reveal_strategy(board)

        # ================== ç¿»å­ç­–ç•¥ ==================

    def _reveal_strategy(self, board):
        """æ¨¡æ“¬ç¿»å­æœŸæœ›å€¼ï¼ŒæŒ‘å‡ºæœ€æœ‰åˆ©çš„ç¿»å­ä½ç½®"""
        dark_positions = board.get_dark_positions()
        if not dark_positions:
            return random.choice(board.availables)  # æ²’å¾—ç¿»å°±éš¨ä¾¿èµ°

        best_pos = None
        best_value = -float('inf')

        for pos in dark_positions:
            expected_value = self._simulate_reveal(board, pos)
            if expected_value > best_value:
                best_value = expected_value
                best_pos = pos

        r, c = best_pos
        action = f"{r}{c}{r}{c}"
        return move_action2move_id[action]

    def _simulate_reveal(self, board, pos):
        """æ¨¡æ“¬ç¿»å‡ºä¸åŒæ£‹å­å¾Œçš„æœŸæœ›å€¼ï¼ˆçµåˆæ–°æœå°‹æ³•ï¼‰"""
        re_pieces = board.remain_pieces
        if not re_pieces:
            return 0

        # çµ±è¨ˆæ£‹ç¨®æ©Ÿç‡
        counts = {}
        for p in re_pieces:
            counts[p] = counts.get(p, 0) + 1
        total = len(re_pieces)
        possible_pieces = {p: c / total for p, c in counts.items()}

        total_value = 0
        for piece, prob in possible_pieces.items():
            backup = self._backup_board(board)
            board.force_reveal(pos, piece)

            # ğŸ”„ æ”¹æˆå‘¼å«æ–°æœå°‹å™¨ search_upward
            score = self.search_upward(
                board, depth=2,
                alpha=-float('inf'),
                beta=float('inf'),
                side_player_id=board.current_player_id,
                maxDepth=2
            )

            total_value += prob * score
            self._restore_board(board, backup)

        return total_value

    # ====================== è©•ä¼°èˆ‡å‚™ä»½ ======================
    def evaluate(self, board, winner=None):
        """ç›¤é¢è©•ä¼°"""
        if winner == self.player:
            return 9999
        elif winner != -1 and winner != self.player:
            return -9999

        red_strength = board.calc_side_strength('çº¢')
        black_strength = board.calc_side_strength('é»‘')
        return red_strength - black_strength if self.player == 1 else black_strength - red_strength

    def _backup_board(self, board):
        """å‚™ä»½æ£‹ç›¤ç‹€æ…‹"""
        return {
            "state_deque": copy.deepcopy(board.state_deque),
            "remain_pieces": copy.deepcopy(board.remain_pieces),
            "current_player_color": board.current_player_color,
            "current_player_id": board.current_player_id,
            "last_move": board.last_move,
            "winner": board.winner,
            "kill_action": board.kill_action,
            "first_move": board.first_move,
            "action_count": board.action_count,
        }

    def _restore_board(self, board, backup):
        """é‚„åŸæ£‹ç›¤ç‹€æ…‹"""
        board.state_deque = backup["state_deque"]
        board.remain_pieces = backup["remain_pieces"]
        board.current_player_color = backup["current_player_color"]
        board.current_player_id = backup["current_player_id"]
        board.last_move = backup["last_move"]
        board.winner = backup["winner"]
        board.kill_action = backup["kill_action"]
        board.first_move = backup["first_move"]
        board.action_count = backup["action_count"]


class ChatGPTPlayer:
    def __init__(self, model="gpt-4o-mini"):
        self.client = OpenAI(api_key="")  # æ”¾ API Key

        self.model = model
        self.agent = 'AI'

    def set_player_ind(self, p):
        self.player = p

    def board_to_state(self, _state_array):
        # _state_array: [10, 9, 7], HWC
        all_board = []

        for i in range(4):
            board_line = []
            for j in range(8):
                board_line.append(array2string(_state_array[i][j]))
            all_board.append(board_line)
        return all_board

    def get_action(self, board):
        # è½‰æ›æ£‹ç›¤
        state_text = self.board_to_state(state_list2state_array(board.state_deque[-1]))

        # æŠŠæ‰€æœ‰åˆæ³•è¡Œå‹•åˆ—å‡ºä¾†
        eat_move_list, fallback_movelist = board.greedys()
        all_moves = eat_move_list + fallback_movelist
        all_moves_relabel = [move_id2move_action[m] for m in all_moves]
        # ç”Ÿæˆ prompt
        # print(all_moves_relabel)
        prompt = f"""
ä½ æ­£åœ¨ç©ä¸­åœ‹æš—æ£‹ (4x8)ã€‚
ç¾åœ¨æ£‹ç›¤ç‹€æ…‹å¦‚ä¸‹ï¼š
{state_text}

å¯è¡Œçš„å‹•ä½œæœ‰ï¼š
{all_moves_relabel} 
æ ¼å¼æ˜¯4å€‹æ•¸å­— ABCD ABç‚ºèµ·å§‹ä½ç½® CDç‚ºçµæŸä½ç½® è‹¥A=C B=Då‰‡ä»£è¡¨ç¿»æ£‹

è«‹å¾ä¸­é¸æ“‡ä¸€å€‹æœ€ä½³å‹•ä½œï¼Œç›´æ¥è¼¸å‡ºè©²å‹•ä½œ (ä¸è¦å¤šé¤˜çš„è§£é‡‹)ã€‚
"""

        try:
            # å‘¼å« ChatGPT
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.9
            )
            reply = response.choices[0].message.content.strip()
            reply_str = "".join(str(x) for x in reply if x.isdigit())  # éæ¿¾éæ•¸å­—

            # å˜—è©¦è½‰æ›
            if reply_str in move_action2move_id:
                reply_index = move_action2move_id[reply_str]
                # ç¢ºä¿å‹•ä½œåˆæ³•
                if reply_index in all_moves:
                    return reply_index
                else:
                    print(f"âš ï¸ ChatGPT å›å‚³éæ³•å‹•ä½œ {reply_str}ï¼ˆä¸åœ¨åˆæ³•å‹•ä½œåˆ—è¡¨ï¼‰ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")
            else:
                print(f"âš ï¸ ChatGPT å›å‚³ç„¡æ•ˆå‹•ä½œå­—ä¸² {reply}ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")

        except Exception as e:
            print(f"âš ï¸ ChatGPT API éŒ¯èª¤: {e}ï¼Œæ”¹ç”¨éš¨æ©Ÿå‹•ä½œ")

            # fallback
        return random.choice(all_moves) if all_moves else None

class RandomPlayer:
    def __init__(self):
        self.agent = 'AI'
        self.type = "random"

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        eat_move_list, fallback_move_list = board.greedys()
        all_move = eat_move_list + fallback_move_list
        if not all_move:
            return None
        return random.choice(all_move)


class GreedyPlayer:
    def __init__(self):
        self.agent = 'AI'
        self.type = "greedy"

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        eat_move_list, fallback_move_list = board.greedys()
        if eat_move_list:
            return random.choice(eat_move_list)
        elif fallback_move_list:
            return random.choice(fallback_move_list)
        else:
            return None


class Human:
    def __init__(self):
        self.agent = 'Human'

    def set_player_ind(self, p):
        self.player = p

    def get_action(self, board):
        # UIplay æœƒç”¨ï¼Œé€™è£¡å…ˆæ”¾ä½”ä½
        return None

def evaluate_policy_against_checkpoints(board,
                                        model_dir="models",
                                        start=1000, end=6000, step=1000,
                                        n_games=100,
                                        csv_file="post_policy_evaluate.csv"):
    current_policy = PolicyValueNet(model_file='current_policy.pth')
    current_player = MCTSPlayer(current_policy.policy_value_fn,
                                c_puct=1, n_playout=300, is_selfplay=0)
    current_player.agent = f"Current-policy"

    # ğŸ”¸ å…ˆå»ºç«‹ CSVï¼ˆåªå»ºç«‹ä¸€æ¬¡ï¼‰
    with open(csv_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Opponent", "Wins", "Losses", "Draws"])

    # æ”¶é›†å°æ‰‹ (èˆŠçš„ checkpoint)

    for batch in range(start, end + 1, step):
        opponents = {}
        filename = f"current_policy_batch{batch}.pth"
        path = os.path.join(model_dir, filename)
        if os.path.exists(path):
            old_policy = PolicyValueNet(model_file=path)
            old_player = MCTSPlayer(old_policy.policy_value_fn,
                                    c_puct=1, n_playout=200, is_selfplay=0)
            old_player.agent = f"Batch{batch}"
            opponents[f"Batch{batch}"] = old_player

        # è·‘ battle_summary
        results = battle_summary(current_player, opponents, board, playouts=1000,
                                 n_games=n_games, save_csv=True, csv_file=csv_file, append=True)
    return

def battle_summary(player1, opponents, board, playouts, n_games=100,
                   save_csv=True, csv_file="battle_summary.csv"):
    """
    å°æ¯å€‹å°æ‰‹é€²è¡Œå°æˆ°ä¸¦è¨˜éŒ„çµæœã€‚
    è‹¥ CSV å·²å­˜åœ¨ï¼Œå‰‡åªæœƒè¿½åŠ æ–°å°æ‰‹çš„çµæœï¼ˆä¸è¦†è“‹èˆŠè³‡æ–™ï¼‰ã€‚
    """
    game = Game(board)
    results = {}

    existing_opponents = set()
    writer = None
    f = None

    # --- æª¢æŸ¥æ˜¯å¦å·²æœ‰çµæœæª” ---
    if os.path.exists(csv_file):
        with open(csv_file, "r", encoding="utf-8") as f_read:
            reader = csv.reader(f_read)
            next(reader, None)  # skip header
            for row in reader:
                if len(row) >= 1:
                    existing_opponents.add(row[0])

    # --- é–‹å•Ÿ CSV æª”æ¡ˆ ---
    if save_csv:
        file_exists = os.path.exists(csv_file)
        f = open(csv_file, "a", newline="", encoding="utf-8")
        writer = csv.writer(f)
        # å¦‚æœæ˜¯æ–°æª”æ¡ˆå°±å¯«å…¥æ¨™é ­
        if not file_exists:
            writer.writerow(["Opponent", "Wins", "Losses", "Draws"])

    # --- é€ä¸€å°æˆ° ---
    for opp_name, player2 in opponents.items():
        if opp_name in existing_opponents:
            print(f"âš ï¸ {opp_name} å·²å­˜åœ¨æ–¼ {csv_file}ï¼Œè·³éã€‚")
            continue

        stats = {"win": 0, "loss": 0, "draw": 0}
        print(f"âš”ï¸ {player1.agent} vs {opp_name} é–‹å§‹å°æˆ°ï¼Œå…± {n_games} å ´...")

        for i in range(n_games):
            board.init_board(1)
            players = {1: player1, 2: player2}

            # è¼ªæµå…ˆæ‰‹
            if i % 2 == 0:
                player1.set_player_ind(1)
                player2.set_player_ind(2)
            else:
                player1.set_player_ind(2)
                player2.set_player_ind(1)

            while True:
                move = players[board.current_player_id].get_action(board)
                if move is None:
                    break
                board.do_move(move)
                end, winner = board.game_end()
                if end:
                    print(f"ç¬¬{i}å ´çµæŸ")
                    if winner == -1:
                        stats["draw"] += 1
                    elif players[winner] == player1:
                        stats["win"] += 1
                    else:
                        stats["loss"] += 1
                    break

        results[opp_name] = stats
        print(f"âœ… {player1.agent} vs {opp_name} å®Œæˆ: {stats}")

        # --- å¯«å…¥çµæœ ---
        if writer:
            writer.writerow([opp_name, stats["win"], stats["loss"], stats["draw"]])
            f.flush()

    if f:
        f.close()
        print(f"ğŸ“Š å°æˆ°çµæœå·²æ›´æ–°è‡³ {csv_file}")

    return results
def battle_capture_summary(player1, opponents, board, n_games=100, save_csv=True, csv_file="battle_capture_summary.csv"):
    """
    å°æˆ°çµ±è¨ˆï¼ˆå«é›™æ–¹åƒæ£‹æ¯”ä¾‹ï¼‰
    è¨˜éŒ„æ¯å€‹å°æ‰‹çš„å¹³å‡åƒæ£‹æ¯”ä¾‹ = åƒæ£‹æ•¸ / ç¸½æ­¥æ•¸
    åˆ†åˆ¥çµ±è¨ˆ player1 èˆ‡å°æ‰‹é›™æ–¹ã€‚
    """
    game = Game(board)
    results = {}

    # --- åˆå§‹åŒ– CSV ---
    if save_csv:
        f = open(csv_file, "w", newline="", encoding="utf-8")
        writer = csv.writer(f)
        writer.writerow([
            "Opponent",
            "Wins", "Losses", "Draws",
            "Player1_CaptureRate", "Opponent_CaptureRate"
        ])
    else:
        writer = None
        f = None

    # --- ä¸»å›åœˆ ---
    for opp_name, player2 in opponents.items():
        stats = {"win": 0, "loss": 0, "draw": 0}
        p1_capture_rates = []  # player1 å¹³å‡åƒæ£‹æ¯”ä¾‹
        p2_capture_rates = []  # å°æ‰‹ å¹³å‡åƒæ£‹æ¯”ä¾‹

        print(f"âš”ï¸ {player1.agent} vs {opp_name} é–‹å§‹å°æˆ°ï¼Œå…± {n_games} å ´...")

        for i in range(n_games):
            board.init_board(1)
            players = {1: player1, 2: player2}

            # æ¯å ´åˆå§‹åŒ–
            total_moves = {1: 0, 2: 0}
            total_captures = {1: 0, 2: 0}

            # è¼ªæµå…ˆæ‰‹
            if i % 2 == 0:
                player1.set_player_ind(1); player2.set_player_ind(2)
            else:
                player1.set_player_ind(2); player2.set_player_ind(1)

            # --- å°æˆ° ---
            while True:
                cur_id = board.current_player_id
                move = players[cur_id].get_action(board)
                if move is None:
                    break

                y1, x1, y2, x2 = map(int, move_id2move_action[move])
                start = board.state_deque[-1][y1][x1]
                target = board.state_deque[-1][y2][x2]

                # åˆ¤å®šæ˜¯å¦åƒæ£‹
                if target not in ('ä¸€ä¸€', 'æš—æ£‹') and board.current_player_color not in target:
                    total_captures[cur_id] += 1

                total_moves[cur_id] += 1
                board.do_move(move)

                end, winner = board.game_end()
                if end:
                    print(f"ç¬¬{i}å ´çµæŸ")
                    if winner == -1:
                        stats["draw"] += 1
                    elif players[winner] == player1:
                        stats["win"] += 1
                    else:
                        stats["loss"] += 1
                    break

            # --- è¨ˆç®—æœ¬å ´åƒæ£‹æ¯”ä¾‹ ---
            p1_id = player1.player
            p2_id = player2.player

            p1_rate = (total_captures[p1_id] / total_moves[p1_id]) if total_moves[p1_id] > 0 else 0
            p2_rate = (total_captures[p2_id] / total_moves[p2_id]) if total_moves[p2_id] > 0 else 0

            p1_capture_rates.append(p1_rate)
            p2_capture_rates.append(p2_rate)

        # --- å ´å‡ ---
        avg_p1_rate = sum(p1_capture_rates) / len(p1_capture_rates)
        avg_p2_rate = sum(p2_capture_rates) / len(p2_capture_rates)

        results[opp_name] = {
            **stats,
            "p1_capture_rate": avg_p1_rate,
            "p2_capture_rate": avg_p2_rate
        }

        print(f"âœ… {player1.agent} vs {opp_name} å®Œæˆ: {stats}")
        print(f"  Player1 å¹³å‡åƒæ£‹æ¯”ä¾‹ = {avg_p1_rate:.3f}")
        print(f"  {opp_name} å¹³å‡åƒæ£‹æ¯”ä¾‹ = {avg_p2_rate:.3f}")

        # --- å¯«å…¥ CSV ---
        if writer:
            writer.writerow([
                opp_name,
                stats["win"], stats["loss"], stats["draw"],
                f"{avg_p1_rate:.3f}", f"{avg_p2_rate:.3f}"
            ])
            f.flush()

    # --- çµå°¾ ---
    if f:
        f.close()
        print(f"ğŸ“Š å°æˆ°çµæœï¼ˆå«é›™æ–¹åƒæ£‹æ¯”ä¾‹ï¼‰å·²å­˜åˆ° {csv_file}")

    return results

def plot_battle_results_from_csv(csv_file="battle_summary.csv"):
    import csv
    import matplotlib.pyplot as plt

    opponents = []
    wins = []

    # --- è®€å– CSV ---
    with open(csv_file, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            opponents.append(row["Opponent"])
            wins.append(int(row["Wins"]))

    # --- æ ¹æ“šå‹å ´æ•¸æ’åº ---
    sorted_data = sorted(zip(opponents, wins), key=lambda x: x[1], reverse=True)
    opponents, wins = zip(*sorted_data)

    # --- å®šç¾©ä¸åŒçš„å¡«å……æ¨£å¼ (hatch patterns) ---
    hatch_patterns = ["//", "\\\\", "xx", "oo", "--", "++", "..", "**"]
    hatch_patterns = (hatch_patterns * ((len(opponents) // len(hatch_patterns)) + 1))[:len(opponents)]

    # --- ç•«åœ– ---
    fig, ax = plt.subplots(figsize=(8, 5))

    bars = []
    for i, (opponent, win) in enumerate(zip(opponents, wins)):
        bar = ax.bar(opponent, win, color="white", edgecolor="black", hatch=hatch_patterns[i])
        bars.append(bar)

    ax.set_xlabel("å°æ‰‹ç­–ç•¥", fontsize=12)
    ax.set_ylabel("å‹åˆ©å ´æ•¸", fontsize=12)
    ax.set_title("å°æˆ°çµæœ", fontsize=14)
    ax.set_ylim(0, max(wins) + 5)

    # åœ¨æŸ±ç‹€åœ–ä¸ŠåŠ æ•¸å­—
    for bar, v in zip(bars, wins):
        ax.text(bar[0].get_x() + bar[0].get_width() / 2, v + 0.5, str(v),
                ha="center", va="bottom", fontsize=10)

    plt.tight_layout()
    plt.show()

if __name__ == '__main__':

    plot_battle_results_from_csv()